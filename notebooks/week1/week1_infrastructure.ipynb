{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# PaperAlchemy - Week 1: Infrastructure Setup\n",
    "\n",
    "Build a production-grade RAG system for academic paper discovery using Docker, PostgreSQL, OpenSearch, FastAPI, Airflow, Ollama, and Langfuse.\n",
    "\n",
    "## Technology Stack\n",
    "| Component | Purpose | Port |\n",
    "|-----------|---------|------|\n",
    "| **FastAPI** | REST API | 8000 |\n",
    "| **PostgreSQL** | Paper metadata storage | 5433 |\n",
    "| **Redis** | Caching layer | 6380 |\n",
    "| **OpenSearch** | Hybrid search engine | 9201/5602 |\n",
    "| **Apache Airflow** | Workflow automation | 8080 |\n",
    "| **Ollama** | Local LLM inference | 11434 |\n",
    "| **Langfuse** | RAG monitoring & tracing | 3001 |\n",
    "| **ClickHouse** | Analytics database | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learning-materials",
   "metadata": {},
   "source": [
    "## Learning Materials\n",
    "\n",
    "**Core Technologies:**\n",
    "- **Docker**: [Tutorial Video](https://www.youtube.com/watch?v=pg19Z8LL06w) | [Docker Compose](https://www.youtube.com/watch?v=SXwC9fSwct8)\n",
    "- **FastAPI**: [YouTube Series](https://www.youtube.com/playlist?list=PLK8U0kF0E_D6l19LhOGWhVZ3sQ6ujJKq_) | [Documentation](https://fastapi.tiangolo.com/tutorial/)\n",
    "- **PostgreSQL**: [Beginners Guide](https://www.youtube.com/watch?v=SpfIwlAYaKk) | [FastAPI + PostgreSQL](https://www.youtube.com/watch?v=398DuQbQJq0)\n",
    "- **OpenSearch**: [Getting Started](https://docs.opensearch.org/latest/getting-started/)\n",
    "- **Apache Airflow**: [Tutorial Video](https://www.youtube.com/watch?v=Y_vQyMljDsE)\n",
    "- **Langfuse**: [Documentation](https://langfuse.com/docs)\n",
    "\n",
    "**Development Tools:**\n",
    "- **VS Code Setup**: [Video Guide](https://www.youtube.com/watch?v=mpk4Q5feWaw)\n",
    "- **Git Basics**: [Tutorial](https://www.youtube.com/watch?v=zTjRZNkhiEU)\n",
    "- **UV Package Manager**: [Setup Video](https://www.youtube.com/watch?v=AMdG7IjgSPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Required Software:**\n",
    "- Python 3.12+ ([Download](https://www.python.org/downloads/))\n",
    "- UV Package Manager ([Install Guide](https://docs.astral.sh/uv/getting-started/installation/))\n",
    "- Docker Desktop ([Download](https://docs.docker.com/get-docker/))\n",
    "- Git ([Download](https://git-scm.com/downloads))\n",
    "\n",
    "**System Requirements:**\n",
    "- 8GB+ RAM (16GB recommended)\n",
    "- 20GB+ free disk space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-intro",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "**Before running cells:**\n",
    "1. Extract/clone project to your system\n",
    "2. Open terminal in project root (contains `compose.yml`)\n",
    "3. Run: `uv sync`\n",
    "4. Start all services: `docker compose up -d`\n",
    "5. **Start Jupyter with UV**: `uv run jupyter notebook`\n",
    "\n",
    "**Important:** Always start Jupyter with `uv run jupyter notebook` to use the project's virtual environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-check-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.12.7\n",
      "Environment: /Users/nishantgaurav/Project/PaperAlchemy/.venv/bin/python\n",
      "✓ Running in project virtual environment\n",
      "✓ Python version compatible\n"
     ]
    }
   ],
   "source": [
    "# Environment Check\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "python_version = sys.version_info\n",
    "print(f\"Python Version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "print(f\"Environment: {sys.executable}\")\n",
    "\n",
    "# Check if running in project's virtual environment\n",
    "if '.venv' in sys.executable:\n",
    "    print(\"✓ Running in project virtual environment\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: Not running in project .venv!\")\n",
    "    print(\"  Restart Jupyter with: uv run jupyter notebook\")\n",
    "\n",
    "if python_version >= (3, 12):\n",
    "    print(\"✓ Python version compatible\")\n",
    "else:\n",
    "    print(\"✗ Need Python 3.12+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "project-root",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project root: /Users/nishantgaurav/Project/PaperAlchemy\n"
     ]
    }
   ],
   "source": [
    "# Find Project Root\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "if current_dir.name == \"week1\" and current_dir.parent.name == \"notebooks\":\n",
    "    project_root = current_dir.parent.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = None\n",
    "\n",
    "if project_root and (project_root / \"compose.yml\").exists():\n",
    "    print(f\"✓ Project root: {project_root}\")\n",
    "else:\n",
    "    print(\"✗ Missing compose.yml - check directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "docker-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Docker: Docker version 28.4.0, build d8eb465\n"
     ]
    }
   ],
   "source": [
    "# Check Docker\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([\"docker\", \"--version\"], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ Docker: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"✗ Docker: Not working\")\n",
    "except:\n",
    "    print(\"✗ Docker: Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "docker-compose-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Docker Compose: Docker Compose version v2.39.4-desktop.1\n"
     ]
    }
   ],
   "source": [
    "# Check Docker Compose\n",
    "try:\n",
    "    result = subprocess.run([\"docker\", \"compose\", \"version\"], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ Docker Compose: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"✗ Docker Compose: Not working\")\n",
    "except:\n",
    "    print(\"✗ Docker Compose: Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uv-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ UV: uv 0.8.23 (Homebrew 2025-10-04)\n",
      "\n",
      "✓ All required software ready!\n"
     ]
    }
   ],
   "source": [
    "# Check UV Package Manager\n",
    "try:\n",
    "    result = subprocess.run([\"uv\", \"--version\"], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ UV: {result.stdout.strip()}\")\n",
    "        print(\"\\n✓ All required software ready!\")\n",
    "    else:\n",
    "        print(\"✗ UV: Not working\")\n",
    "except:\n",
    "    print(\"✗ UV: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "services-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Docker Services Status\n",
    "\n",
    "**Command to run (in terminal):**\n",
    "```bash\n",
    "cd [project-root]\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "This will start all 12 services including the FastAPI application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "docker-running",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Docker is running\n"
     ]
    }
   ],
   "source": [
    "# Check Docker Running\n",
    "try:\n",
    "    result = subprocess.run([\"docker\", \"info\"], capture_output=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ Docker is running\")\n",
    "    else:\n",
    "        print(\"✗ Docker not running - start Docker Desktop\")\n",
    "except:\n",
    "    print(\"✗ Docker daemon not accessible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "container-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DOCKER SERVICE STATUS\n",
      "======================================================================\n",
      "Container                           State        Health\n",
      "----------------------------------------------------------------------\n",
      "✓ paperalchemy-airflow              running      healthy\n",
      "✓ paperalchemy-api                  running      healthy\n",
      "✓ paperalchemy-clickhouse           running      healthy\n",
      "✓ paperalchemy-dashboards           running      healthy\n",
      "⚠ paperalchemy-langfuse             running      unhealthy\n",
      "✓ paperalchemy-langfuse-minio       running      healthy\n",
      "✓ paperalchemy-langfuse-postgres    running      healthy\n",
      "✓ paperalchemy-langfuse-redis       running      healthy\n",
      "✓ paperalchemy-ollama               running      healthy\n",
      "✓ paperalchemy-opensearch           running      healthy\n",
      "✓ paperalchemy-postgres             running      healthy\n",
      "✓ paperalchemy-redis                running      healthy\n",
      "\n",
      "✓ All Docker services running!\n"
     ]
    }
   ],
   "source": [
    "# Check Docker Containers\n",
    "import json\n",
    "\n",
    "EXPECTED_DOCKER_SERVICES = [\n",
    "    'paperalchemy-api',\n",
    "    'paperalchemy-postgres',\n",
    "    'paperalchemy-redis',\n",
    "    'paperalchemy-opensearch',\n",
    "    'paperalchemy-dashboards',\n",
    "    'paperalchemy-ollama',\n",
    "    'paperalchemy-airflow',\n",
    "    'paperalchemy-clickhouse',\n",
    "    'paperalchemy-langfuse',\n",
    "    'paperalchemy-langfuse-postgres',\n",
    "    'paperalchemy-langfuse-redis',\n",
    "    'paperalchemy-langfuse-minio'\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"compose\", \"ps\", \"--format\", \"json\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=15\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"DOCKER SERVICE STATUS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Container':<35} {'State':<12} {'Health'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    running_services = set()\n",
    "    service_states = {}\n",
    "    \n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    container = json.loads(line)\n",
    "                    name = container.get('Name', 'unknown')\n",
    "                    state = container.get('State', 'unknown')\n",
    "                    health = container.get('Health', '-')\n",
    "                    running_services.add(name)\n",
    "                    service_states[name] = {'state': state, 'health': health}\n",
    "                    \n",
    "                    if state == 'running' and health in ['healthy', '-']:\n",
    "                        icon = \"✓\"\n",
    "                    elif state == 'running':\n",
    "                        icon = \"⚠\"\n",
    "                    else:\n",
    "                        icon = \"✗\"\n",
    "                    \n",
    "                    print(f\"{icon} {name:<33} {state:<12} {health}\")\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Check missing Docker services\n",
    "    missing = set(EXPECTED_DOCKER_SERVICES) - running_services\n",
    "    if missing:\n",
    "        print(\"\\nMISSING DOCKER SERVICES:\")\n",
    "        for s in sorted(missing):\n",
    "            print(f\"  ✗ {s}\")\n",
    "        print(\"\\n  Run: docker compose up -d\")\n",
    "    else:\n",
    "        print(\"\\n✓ All Docker services running!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fastapi-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. FastAPI - REST API Service\n",
    "\n",
    "The FastAPI application runs in Docker as part of `docker compose up -d`.\n",
    "\n",
    "**Interactive Exploration:**\n",
    "- **API Documentation**: http://localhost:8000/docs (Interactive Swagger UI)\n",
    "- **Alternative Docs**: http://localhost:8000/redoc (ReDoc interface)\n",
    "- **Source Code**: Located in `src/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fastapi-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FastAPI is responding\n",
      "  Status: healthy\n",
      "  Debug: True\n",
      "\n",
      "  API Docs: http://localhost:8000/docs\n"
     ]
    }
   ],
   "source": [
    "# Test FastAPI Health\n",
    "import httpx\n",
    "\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:8000/health\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"✓ FastAPI is responding\")\n",
    "        print(f\"  Status: {data.get('status', 'unknown')}\")\n",
    "        print(f\"  Debug: {data.get('debug', 'unknown')}\")\n",
    "        print(f\"\\n  API Docs: http://localhost:8000/docs\")\n",
    "    else:\n",
    "        print(f\"⚠ API returned status: {response.status_code}\")\n",
    "except httpx.ConnectError:\n",
    "    print(\"✗ API not responding\")\n",
    "    print(\"\\n  Check if container is running:\")\n",
    "    print(\"  docker compose ps api\")\n",
    "    print(\"\\n  Start it with:\")\n",
    "    print(\"  docker compose up -d api\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ API test error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postgres-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. PostgreSQL - Database Storage\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "PostgreSQL stores all structured data for our application:\n",
    "- **Connection**: localhost:5433\n",
    "- **Database**: paperalchemy\n",
    "- **Username/Password**: paperalchemy / paperalchemy_secret\n",
    "- **GUI Tool Recommendation**: DBeaver (free database client)\n",
    "\n",
    "Let's test the database connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "postgres-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PostgreSQL connected\n",
      "  Version: PostgreSQL 16.10 on aarch64-unknown-linux-musl\n",
      "  Port: 5433\n",
      "\n",
      "  Connection Details:\n",
      "  • Host: localhost\n",
      "  • Port: 5433\n",
      "  • Database: paperalchemy\n",
      "  • Username: paperalchemy\n",
      "  • Password: paperalchemy_secret\n"
     ]
    }
   ],
   "source": [
    "# Test PostgreSQL Connection\n",
    "try:\n",
    "    import psycopg2\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"paperalchemy\",\n",
    "        user=\"paperalchemy\",\n",
    "        password=\"paperalchemy_secret\"\n",
    "    )\n",
    "    \n",
    "    print(\"✓ PostgreSQL connected\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    version = cursor.fetchone()[0]\n",
    "    print(f\"  Version: {version.split(',')[0]}\")\n",
    "    print(f\"  Port: 5433\")\n",
    "    \n",
    "    print(\"\\n  Connection Details:\")\n",
    "    print(\"  • Host: localhost\")\n",
    "    print(\"  • Port: 5433\")\n",
    "    print(\"  • Database: paperalchemy\")\n",
    "    print(\"  • Username: paperalchemy\")\n",
    "    print(\"  • Password: paperalchemy_secret\")\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"✗ psycopg2 not installed\")\n",
    "    print(\"\\n  You're not using the project's virtual environment!\")\n",
    "    print(\"  Restart Jupyter with: uv run jupyter notebook\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "postgres-tables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 tables in public schema\n",
      "  • ab_permission\n",
      "  • ab_permission_view\n",
      "  • ab_permission_view_role\n",
      "  • ab_register_user\n",
      "  • ab_role\n",
      "  • ab_user\n",
      "  • ab_user_role\n",
      "  • ab_view_menu\n",
      "  • alembic_version\n",
      "  • callback_request\n",
      "  ... and 38 more\n"
     ]
    }
   ],
   "source": [
    "# Check Database Tables\n",
    "try:\n",
    "    import psycopg2\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\", port=5433,\n",
    "        database=\"paperalchemy\",\n",
    "        user=\"paperalchemy\", password=\"paperalchemy_secret\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name;\n",
    "    \"\"\")\n",
    "    \n",
    "    tables = cursor.fetchall()\n",
    "    print(f\"Found {len(tables)} tables in public schema\")\n",
    "    \n",
    "    for (table_name,) in tables[:10]:  # Show first 10\n",
    "        print(f\"  • {table_name}\")\n",
    "    \n",
    "    if len(tables) > 10:\n",
    "        print(f\"  ... and {len(tables) - 10} more\")\n",
    "    \n",
    "    if not tables:\n",
    "        print(\"  No application tables yet (expected in Week 1)\")\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"✗ psycopg2 not installed - restart Jupyter with: uv run jupyter notebook\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not check tables: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "redis-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Redis - Cache Layer\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "Redis provides fast caching for our application:\n",
    "- **Connection**: localhost:6380\n",
    "- **Purpose**: Session caching, query results caching\n",
    "\n",
    "Let's test Redis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "redis-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Redis connected\n",
      "  Port: 6380\n",
      "  Test write/read: PaperAlchemy\n",
      "  Redis version: 7.4.6\n",
      "  Connected clients: 1\n"
     ]
    }
   ],
   "source": [
    "# Test Redis Connection\n",
    "try:\n",
    "    import redis\n",
    "    \n",
    "    r = redis.Redis(host=\"localhost\", port=6380)\n",
    "    r.ping()\n",
    "    print(\"✓ Redis connected\")\n",
    "    print(f\"  Port: 6380\")\n",
    "    \n",
    "    # Test basic operations\n",
    "    r.set(\"test_key\", \"PaperAlchemy\")\n",
    "    value = r.get(\"test_key\")\n",
    "    print(f\"  Test write/read: {value.decode()}\")\n",
    "    r.delete(\"test_key\")\n",
    "    \n",
    "    info = r.info()\n",
    "    print(f\"  Redis version: {info.get('redis_version')}\")\n",
    "    print(f\"  Connected clients: {info.get('connected_clients')}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"✗ redis not installed - restart Jupyter with: uv run jupyter notebook\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Redis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opensearch-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. OpenSearch - Hybrid Search Engine\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "OpenSearch provides full-text search and analytics capabilities:\n",
    "- **API Endpoint**: http://localhost:9201\n",
    "- **Dashboards UI**: http://localhost:5602 (Web interface)\n",
    "\n",
    "**Important for Students:**\n",
    "- Use http://localhost:5602 for web interface\n",
    "- Use Dev Tools in Dashboards for API queries\n",
    "\n",
    "Let's test OpenSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opensearch-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenSearch connected\n",
      "  Cluster: docker-cluster\n",
      "  Version: 2.19.0\n",
      "  Port: 9201\n"
     ]
    }
   ],
   "source": [
    "# Test OpenSearch Connection\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:9201\", timeout=15)\n",
    "    if response.status_code == 200:\n",
    "        info = response.json()\n",
    "        print(\"✓ OpenSearch connected\")\n",
    "        print(f\"  Cluster: {info.get('cluster_name')}\")\n",
    "        print(f\"  Version: {info.get('version', {}).get('number')}\")\n",
    "        print(f\"  Port: 9201\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"⚠ OpenSearch timeout - service may be slow\")\n",
    "    print(\"  Try running this cell again\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ OpenSearch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opensearch-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Cluster health: yellow\n",
      "  Nodes: 1\n",
      "  Active shards: 5\n"
     ]
    }
   ],
   "source": [
    "# Check OpenSearch Cluster Health\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:9201/_cluster/health\", timeout=15)\n",
    "    if response.status_code == 200:\n",
    "        health = response.json()\n",
    "        status = health.get('status')\n",
    "        icon = \"✓\" if status == \"green\" else \"⚠\" if status == \"yellow\" else \"✗\"\n",
    "        print(f\"{icon} Cluster health: {status}\")\n",
    "        print(f\"  Nodes: {health.get('number_of_nodes')}\")\n",
    "        print(f\"  Active shards: {health.get('active_shards')}\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"⚠ Health check timeout - try again\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Health check failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opensearch-dashboards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenSearch Dashboards is accessible!\n",
      "✓ Web interface is ready for exploration\n",
      "\n",
      "  Web Interface Access:\n",
      "  ========================================\n",
      "  Main Dashboard: http://localhost:5602\n",
      "  Dev Tools: http://localhost:5602/app/dev_tools\n",
      "  ========================================\n",
      "\n",
      "  Student Learning Activities:\n",
      "  1. Explore the Dashboard:\n",
      "     • Visit http://localhost:5602\n",
      "     • Navigate through the interface\n",
      "     • Check out the 'Discover' tab\n",
      "\n",
      "  2. Use Dev Tools for API Queries:\n",
      "     • Go to Dev Tools\n",
      "     • Try: GET /_cluster/health\n",
      "     • Try: GET /_cat/indices?v\n"
     ]
    }
   ],
   "source": [
    "# Test OpenSearch Dashboards\n",
    "import requests\n",
    "\n",
    "dashboards_url = \"http://localhost:5602\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{dashboards_url}/api/status\", timeout=15, allow_redirects=True)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✓ OpenSearch Dashboards is accessible!\")\n",
    "        print(\"✓ Web interface is ready for exploration\")\n",
    "        \n",
    "        print(\"\\n  Web Interface Access:\")\n",
    "        print(\"  \" + \"=\" * 40)\n",
    "        print(f\"  Main Dashboard: {dashboards_url}\")\n",
    "        print(f\"  Dev Tools: {dashboards_url}/app/dev_tools\")\n",
    "        print(\"  \" + \"=\" * 40)\n",
    "        \n",
    "        print(\"\\n  Student Learning Activities:\")\n",
    "        print(\"  1. Explore the Dashboard:\")\n",
    "        print(\"     • Visit http://localhost:5602\")\n",
    "        print(\"     • Navigate through the interface\")\n",
    "        print(\"     • Check out the 'Discover' tab\")\n",
    "        \n",
    "        print(\"\\n  2. Use Dev Tools for API Queries:\")\n",
    "        print(\"     • Go to Dev Tools\")\n",
    "        print(\"     • Try: GET /_cluster/health\")\n",
    "        print(\"     • Try: GET /_cat/indices?v\")\n",
    "    else:\n",
    "        print(f\"⚠ Dashboards returned status: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"✗ OpenSearch Dashboards not accessible yet\")\n",
    "    print(\"  Wait 2-3 minutes for full startup\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ollama-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Ollama - Local LLM Inference Engine\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "Ollama runs large language models locally on your machine:\n",
    "- **API Endpoint**: http://localhost:11434\n",
    "- **Command Line**: Available inside the container\n",
    "- **Privacy**: All AI processing happens locally (no external APIs)\n",
    "\n",
    "Let's test Ollama and see what models are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ollama-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama is running!\n",
      "  Available models: 1\n",
      "\n",
      "  Installed Models:\n",
      "    • llama3.2:1b (1.2 GB)\n"
     ]
    }
   ],
   "source": [
    "# Test Ollama Service Status\n",
    "ollama_url = \"http://localhost:11434/api/tags\"\n",
    "\n",
    "try:\n",
    "    response = httpx.get(ollama_url, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        models_data = response.json()\n",
    "        models = models_data.get('models', [])\n",
    "        \n",
    "        print(\"✓ Ollama is running!\")\n",
    "        print(f\"  Available models: {len(models)}\")\n",
    "        \n",
    "        if models:\n",
    "            print(\"\\n  Installed Models:\")\n",
    "            for model in models:\n",
    "                name = model.get('name', 'unknown')\n",
    "                size = model.get('size', 0)\n",
    "                size_gb = round(size / (1024**3), 1)\n",
    "                print(f\"    • {name} ({size_gb} GB)\")\n",
    "        else:\n",
    "            print(\"\\n  No models installed yet\")\n",
    "            print(\"  To install a model:\")\n",
    "            print(\"  docker exec paperalchemy-ollama ollama pull llama3.2:1b\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"⚠ Ollama returned status: {response.status_code}\")\n",
    "        \n",
    "except httpx.ConnectError:\n",
    "    print(\"✗ Ollama is not responding yet\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ollama-version",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama API is healthy!\n",
      "  Version: 0.11.2\n",
      "\n",
      "  What is Ollama?\n",
      "  • Runs AI models completely on your local machine\n",
      "  • No data sent to external services (privacy-first)\n",
      "  • No API fees or rate limits\n",
      "  • Supports models like Llama, Mistral, Phi, etc.\n"
     ]
    }
   ],
   "source": [
    "# Check Ollama Version\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:11434/api/version\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        version_data = response.json()\n",
    "        version = version_data.get('version', 'unknown')\n",
    "        \n",
    "        print(\"✓ Ollama API is healthy!\")\n",
    "        print(f\"  Version: {version}\")\n",
    "        \n",
    "        print(\"\\n  What is Ollama?\")\n",
    "        print(\"  • Runs AI models completely on your local machine\")\n",
    "        print(\"  • No data sent to external services (privacy-first)\")\n",
    "        print(\"  • No API fees or rate limits\")\n",
    "        print(\"  • Supports models like Llama, Mistral, Phi, etc.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not check Ollama version: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ollama-pull",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ llama3.2:1b already installed!\n"
     ]
    }
   ],
   "source": [
    "# HANDS-ON: Pull Llama 3.2:1b Model (if not installed)\n",
    "import time\n",
    "\n",
    "# Check if model exists\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "    models = response.json().get('models', [])\n",
    "    model_names = [m.get('name') for m in models]\n",
    "    \n",
    "    if 'llama3.2:1b' in model_names:\n",
    "        print(\"✓ llama3.2:1b already installed!\")\n",
    "    else:\n",
    "        print(\"DOWNLOADING LLAMA 3.2:1B MODEL\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"This is a small 1.3GB model - perfect for testing!\")\n",
    "        print(\"Download will take 2-5 minutes...\")\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"exec\", \"paperalchemy-ollama\", \"ollama\", \"pull\", \"llama3.2:1b\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=600\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n✓ Llama 3.2:1b model downloaded successfully!\")\n",
    "        else:\n",
    "            print(f\"⚠ Download issue: {result.stderr}\")\n",
    "            \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"Download timed out - continues in background\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ollama-generate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing llama3.2:1b with prompt: 'What is machine learning in one sentence?'\n",
      "------------------------------------------------------------\n",
      "Generating response (this may take 10-30 seconds)...\n",
      "Response generated in 18.8 seconds\n",
      "\n",
      "RESPONSE:\n",
      "========================================\n",
      "Machine learning is a subfield of artificial intelligence that enables computers to learn from data, make predictions or decisions without being explicitly programmed, allowing for adaptive and self-improving capabilities.\n",
      "========================================\n",
      "\n",
      "Generation time: 18767ms\n",
      "\n",
      "✓ SUCCESS! Your local AI model is working!\n"
     ]
    }
   ],
   "source": [
    "# Test Llama 3.2:1b Generation\n",
    "import time\n",
    "\n",
    "def test_ollama_model(model_name, prompt, max_wait_time=60):\n",
    "    \"\"\"Test an Ollama model with a prompt.\"\"\"\n",
    "    print(f\"Testing {model_name} with prompt: '{prompt}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"Generating response (this may take 10-30 seconds)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = httpx.post(url, json=data, timeout=max_wait_time)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            response_text = result.get('response', '').strip()\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Response generated in {elapsed_time:.1f} seconds\")\n",
    "            print(\"\\nRESPONSE:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(response_text)\n",
    "            print(\"=\" * 40)\n",
    "            \n",
    "            if 'total_duration' in result:\n",
    "                duration_ms = result['total_duration'] / 1000000\n",
    "                print(f\"\\nGeneration time: {duration_ms:.0f}ms\")\n",
    "                \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"API error: {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except httpx.ConnectError:\n",
    "        print(\"Could not connect to Ollama API\")\n",
    "        return False\n",
    "    except httpx.TimeoutException:\n",
    "        print(\"Request timed out - model might be loading\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test with a simple prompt\n",
    "test_prompt = \"What is machine learning in one sentence?\"\n",
    "success = test_ollama_model(\"llama3.2:1b\", test_prompt)\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✓ SUCCESS! Your local AI model is working!\")\n",
    "else:\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure model downloaded: docker exec paperalchemy-ollama ollama list\")\n",
    "    print(\"2. Check Ollama logs: docker compose logs ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "airflow-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Apache Airflow - Workflow Automation\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "Apache Airflow manages data pipelines and automated workflows:\n",
    "- **Web Dashboard**: http://localhost:8080\n",
    "- **DAGs Location**: `airflow/dags/` directory\n",
    "\n",
    "Let's test Airflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "airflow-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Airflow is healthy\n",
      "  Scheduler: healthy\n",
      "\n",
      "  Airflow Dashboard:\n",
      "  URL: http://localhost:8080\n",
      "  (Check container logs for admin password)\n"
     ]
    }
   ],
   "source": [
    "# Test Airflow Health\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:8080/health\", timeout=15)\n",
    "    if response.status_code == 200:\n",
    "        health = response.json()\n",
    "        print(\"✓ Airflow is healthy\")\n",
    "        print(f\"  Scheduler: {health.get('scheduler', {}).get('status')}\")\n",
    "        print(f\"\\n  Airflow Dashboard:\")\n",
    "        print(f\"  URL: http://localhost:8080\")\n",
    "        print(f\"  (Check container logs for admin password)\")\n",
    "    else:\n",
    "        print(f\"⚠ Airflow returned: {response.status_code}\")\n",
    "        \n",
    "except httpx.ConnectError:\n",
    "    print(\"⚠ Airflow not responding yet\")\n",
    "    print(\"  Airflow takes 3-5 minutes to start\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Airflow: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langfuse-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Langfuse - RAG Monitoring & Tracing\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "Langfuse provides observability for LLM applications:\n",
    "- **Dashboard**: http://localhost:3001\n",
    "- **Login**: admin@paperalchemy.com / admin123\n",
    "- **Purpose**: Trace RAG queries, monitor performance, debug issues\n",
    "\n",
    "Let's test Langfuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "langfuse-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Langfuse is healthy\n",
      "  Status: OK\n",
      "  Version: 3.148.0\n",
      "\n",
      "  Langfuse Dashboard:\n",
      "  URL: http://localhost:3001\n",
      "  Login: admin@paperalchemy.com\n",
      "  Password: admin123\n"
     ]
    }
   ],
   "source": [
    "# Test Langfuse Health\n",
    "try:\n",
    "    response = httpx.get(\"http://localhost:3001/api/public/health\", timeout=15)\n",
    "    if response.status_code == 200:\n",
    "        health = response.json()\n",
    "        print(\"✓ Langfuse is healthy\")\n",
    "        print(f\"  Status: {health.get('status')}\")\n",
    "        print(f\"  Version: {health.get('version')}\")\n",
    "        print(f\"\\n  Langfuse Dashboard:\")\n",
    "        print(f\"  URL: http://localhost:3001\")\n",
    "        print(f\"  Login: admin@paperalchemy.com\")\n",
    "        print(f\"  Password: admin123\")\n",
    "    else:\n",
    "        print(f\"⚠ Langfuse returned: {response.status_code}\")\n",
    "        \n",
    "except httpx.ConnectError:\n",
    "    print(\"⚠ Langfuse not responding yet\")\n",
    "    print(\"  Langfuse takes 2-3 minutes to start\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Langfuse: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "langfuse-postgres-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Langfuse-Postgres connected\n",
      "  Port: 5434\n"
     ]
    }
   ],
   "source": [
    "# Test Langfuse PostgreSQL\n",
    "try:\n",
    "    import psycopg2\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\", port=5434,\n",
    "        user=\"langfuse\", password=\"langfuse\",\n",
    "        database=\"langfuse\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT 1;\")\n",
    "    print(\"✓ Langfuse-Postgres connected\")\n",
    "    print(f\"  Port: 5434\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "except ImportError:\n",
    "    print(\"✗ psycopg2 not installed - restart Jupyter with: uv run jupyter notebook\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Langfuse-Postgres: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clickhouse-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. ClickHouse - Analytics Database\n",
    "\n",
    "ClickHouse powers Langfuse analytics. Let's verify it's running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "clickhouse-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ClickHouse connected\n"
     ]
    }
   ],
   "source": [
    "# Test ClickHouse\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"exec\", \"paperalchemy-clickhouse\", \"clickhouse-client\", \"--query\", \"SELECT 1\"],\n",
    "        capture_output=True, text=True, timeout=10\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ ClickHouse connected\")\n",
    "    else:\n",
    "        print(f\"✗ ClickHouse: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ClickHouse: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Summary & Service URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  PAPERALCHEMY - SERVICE URLS\n",
      "============================================================\n",
      "\n",
      "Main Services:\n",
      "  API Docs:      http://localhost:8000/docs\n",
      "  Airflow:       http://localhost:8080\n",
      "  Langfuse:      http://localhost:3001\n",
      "                 (admin@paperalchemy.com / admin123)\n",
      "\n",
      "Search:\n",
      "  OpenSearch:    http://localhost:9201\n",
      "  Dashboard:     http://localhost:5602\n",
      "\n",
      "LLM:\n",
      "  Ollama:        http://localhost:11434\n",
      "\n",
      "Databases:\n",
      "  PostgreSQL:    localhost:5433 (paperalchemy/paperalchemy_secret)\n",
      "  Redis:         localhost:6380\n",
      "  Langfuse-PG:   localhost:5434 (langfuse/langfuse)\n",
      "\n",
      "============================================================\n",
      "  WEEK 1 COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  PAPERALCHEMY - SERVICE URLS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Main Services:\")\n",
    "print(\"  API Docs:      http://localhost:8000/docs\")\n",
    "print(\"  Airflow:       http://localhost:8080\")\n",
    "print(\"  Langfuse:      http://localhost:3001\")\n",
    "print(\"                 (admin@paperalchemy.com / admin123)\")\n",
    "print()\n",
    "print(\"Search:\")\n",
    "print(\"  OpenSearch:    http://localhost:9201\")\n",
    "print(\"  Dashboard:     http://localhost:5602\")\n",
    "print()\n",
    "print(\"LLM:\")\n",
    "print(\"  Ollama:        http://localhost:11434\")\n",
    "print()\n",
    "print(\"Databases:\")\n",
    "print(\"  PostgreSQL:    localhost:5433 (paperalchemy/paperalchemy_secret)\")\n",
    "print(\"  Redis:         localhost:6380\")\n",
    "print(\"  Langfuse-PG:   localhost:5434 (langfuse/langfuse)\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"  WEEK 1 COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "troubleshooting",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "**Common Issues:**\n",
    "- **ModuleNotFoundError** → Restart Jupyter with: `uv run jupyter notebook`\n",
    "- **Connection refused** → Service still starting (wait 2-3 minutes)\n",
    "- **Port in use** → Stop conflicting application or change ports\n",
    "- **Container restarting** → Check logs: `docker compose logs [service-name]`\n",
    "- **Out of memory** → Increase Docker Desktop memory allocation\n",
    "- **API not responding** → Check: `docker compose ps api` and restart if needed\n",
    "\n",
    "**Reset everything:** `docker compose down && docker compose up -d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commands",
   "metadata": {},
   "source": [
    "---\n",
    "## Project Commands\n",
    "\n",
    "**Makefile shortcuts:**\n",
    "```bash\n",
    "make start    # Start all services\n",
    "make status   # Check service status\n",
    "make logs     # View logs\n",
    "make health   # Check service health\n",
    "make stop     # Stop all services\n",
    "make help     # View all commands\n",
    "```\n",
    "\n",
    "**Docker commands:**\n",
    "```bash\n",
    "docker compose up -d        # Start all services\n",
    "docker compose ps           # Check running containers\n",
    "docker compose logs api     # View API logs\n",
    "docker compose restart api  # Restart API\n",
    "```\n",
    "\n",
    "**Next:** Continue to Week 2 for data ingestion from arXiv!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
